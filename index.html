<!doctype html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang=""> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8" lang=""> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9" lang=""> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <!--<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">-->
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>REMIA: Resource-Efficient Medical Image Analysis</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="apple-touch-icon" href="apple-touch-icon.png">
    <link rel="icon" type="image/png" href="favicon-32x32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="favicon-16x16.png" sizes="16x16" />
    <link rel="stylesheet" href="css/normalize.min.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/social-share-kit.css">
    <link rel="stylesheet" href="css/jquery.fancybox.css">
    <link rel="stylesheet" href="css/flexslider.css">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/queries.css">
    <link rel="stylesheet" href="css/etline-font.css">
    <link rel="stylesheet" href="bower_components/animate.css/animate.min.css">
    <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
    <script src="js/vendor/modernizr-2.8.3-respond-1.4.2.min.js"></script>
</head>
<body id="top">
    <!--[if lt IE 8]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
    <section class="hero">
        <section class="navigation">
            <header>
                <div class="header-content"> 
                    <div class="header-nav">
                        <nav>
                            <a style="color: #E84545"> 
                                <b>REMIA:</b>
                                 MICCAI Workshop on <i><b>R</b>esource-<b>E</b>fficient <b>M</b>edical <b>I</b>mage <b>A</b>nalysis</i>
                            </a> <br>
                            <ul class="primary-nav">
                                <li><a href="#updates">Updates</a></li> 
                                <li><a href="#dates">Dates</a></li>
                                <li><a href="#overview">About</a></li> 
                                <li><a href="#submit">⚡Submission</a></li>
                                <li><a href="https://atlas-challenge.u-bourgogne.fr" target="_blank">⚡ATLAS Challenge</a></li>
                                <li><a href="#program">Program</a></li> 
                                <li><a href="#awards">Awards</a></li> 
                                <li><a href="#people">Organization</a></li>  
                                <li><a href="#previous">Previous REMIA</a></li>  
                                <!-- <li><a href="#sponsors">Sponsor</a></li> -->
                                
                            </ul>
                            <ul class="member-actions">
                                <span style="color:rgb(0, 0, 0)"><a href="https://conferences.miccai.org/2023/" target="_blank">A workshop at &nbsp;</span>
                                <img src="img/logo_miccai3.png" width="75"></a> 
                            </ul>
                        </nav>
                    </div>
                    <div class="navicon">
                        <a class="nav-toggle" href="#"><span></span></a>
                    </div>
                </div>
            </header>

        </section>
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="hero-content text-center">
                        <img src="img/remia-logo.png" height="150">
                        <h1 style="color: #FFF"> 
                            <b>MICCAI Workshop on</b> <br> 
                            <b>2nd Resource-Efficient Medical Image Analysis (REMIA)</b>
                        </h1>
                    </div>
                </div>
            </div>
        </div>
        <div class="down-arrow floating-arrow"><a href="#updates"><i class="fa fa-angle-down"></i></a></div>
    </section>
     
     <section class="intro section-padding" id="updates">
        <div class="container">
            <div class="row">

               <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content">
                        
                        <h2>Recent Updates</h2>
                        <ul>
                            <li>[11/10/23] The zoom link of the REMIA2 workshop + ATLAS challenge is:
<a href="https://ualberta-ca.zoom.us/j/6492916737?pwd=NGFCaE4wV0o3MVZzN3dpYkloYjZpQT09" target="_blank">https://ualberta-ca.zoom.us/j/6492916737?pwd=NGFCaE4wV0o3MVZzN3dpYkloYjZpQT09</a>
                                <br>
                                Meeting ID: 649 291 6737 <br>
Passcode: VisionLear


                            </li>
                            <li> [04/10/23] The REMIA Programme has been released: >>><a href="./REMIA Program_2023.pdf" target="_blank"><strong>Programme</strong></a>. See you in 12th Oct.</li> 
                            <!-- <li> [15/09/22] The REMIA proceedings on Nature Springer has been released: >>><a href="https://link.springer.com/book/10.1007/978-3-031-16876-5" target="_blank"><strong>Proceedings Link</strong></a>.</li> 
                            <li> [25/07/22] The final decisions have been released. Please submit the camera-ready by <strong>Aug 5th</strong>.</li>  -->
                        <li>[01/05/23] In this year, our REMIA workshop will be held in conjunction with "A Tumor and Liver Automatic Segmentation (<strong>ATLAS</strong>)" Challenge in MICCAI. [<a href="https://atlas-challenge.u-bourgogne.fr" target="_blank"><strong>Challenge Link</strong></a>].</li>
                        <li> [01/05/23] Submission system is opened: [<a href="https://cmt3.research.microsoft.com/REMIA2023" target="_blank"><strong>Submission Link</strong></a>] </li> 
                        <li>[15/04/23] In this year, our REMIA workshop will be held by <strong>online only</strong>.</li>
                          <li> [25/02/23] Our <strong>2nd REMIA workshop</strong> has been approval by <a href="https://conferences.miccai.org/2023/" target="_blank"><strong>MICCAI 2023</strong></a>. See you in Vancouver/CANADA! </li> 
                      </ul>
                 </div>
               </div>

            </div>
        </div>
    </section>


    <section class="features dates section-padding" id="dates">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content">
                        <h2>Important Dates</h2> 
                        <ul>
                          <li><span>May 01, 2023</span> <strong>Paper Submission Opening</strong> </li>
                          <li><span><strike>July 05</strike> July 15, 2023</span> <strong>Paper Submission Deadline </strong> 
                            <ul> 
                                <li>Authors are recommended to submit the paper title and abstract in the CMT system by July 1.</li>
                                <li>Allowed submission of rejected main-conference MICCAI papers [in this case, the authors should provide: (1) their original submission, (2) the reviews from the main conference submission, (3) a response to the reviewer comments, and a description of what has changed in the new submission, and (4) their new submission]</li>

                            </ul>
                        </li>
                          <li><span>August 20, 2023</span> <strong>Notification of Paper Decision </strong> </li>

                          <li><span>September 11, 2023</span> <strong>Camera-ready Paper Due </strong> </li>
                          <ul> For Camera-ready Paper, you need to submit:
                            <li>Your camera-ready manuscript with source files in zip file (following MICCAI guideline: <a href="https://conferences.miccai.org/2023/en/CAMERA-READY-GUIDELINES.html" target="_blank">https://conferences.miccai.org/2023/en/CAMERA-READY-GUIDELINES.html</a> )</li>
                            <li>A change/revision list in a text file to address the comments from all reviewers.</li>
                            <li>Signed <strong> LNCS copyright form </strong>,  which the corresponding author can sign on behalf of all authors. (---- Please download the CR form from: <a href="./files/SNCS_ProceedingsPaper_LTP_ST_SN_Switzerland-REMIA 2023.docx" target="_blank">LNCS copyright form</a>)</li>
                            <li>The registration confirmation letter of one author (in PDF file).</li>
                          </ul>

                          <li><span>Oct 8, 2023</span> <strong>REMIA  Workshop </strong> (Online only)</li> 

                          </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

     <section class="intro section-padding" id="overview">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content">
                        <h2>About REMIA Workshop</h2>
                        Resource-Efficient Medical Image Analysis (<strong>REMIA</strong>) is a workshop on International Conference on Medical Image Computing and Computer Assisted Intervention (<strong>MICCAI</strong>)

                        In this year, our REMIA workshop will be held in conjunction with <a href="https://atlas-challenge.u-bourgogne.fr" target="_blank"><strong>"A Tumor and Liver Automatic Segmentation (ATLAS)" Challenge</strong></a>. 
                        
                        <h3>Overview</h3>
                        <p>Deep learning methods have shown remarkable success in many medical imaging tasks over the past few years. However, there exists a challenge that current deep learning models are usually data-hungry, requiring massive amounts of high-quality annotated data to achieve high performance. </p>
                        
                    <p>Firstly, collecting large scale medical imaging datasets is usually expensive and time-consuming, and the regulatory and governance also raise additional challenges for practical healthcare applications. Moreover, the domain shifts in medical data caused by factors such as different medical devices, different subject cohorts and different scanning configurations and conditions have been challenging for deploying the AI models for real-world applications. Secondly, acquiring the data annotations is even more of a challenge as the experienced and knowledgeable clinicians are required to provide high quality annotations. The annotation process is labour-intensive and time-consuming when it comes to the segmentation tasks, especially for 3D medical data, such as CT, OCT and MRI scans etc.. Minutes to hours may be required for the clinicians to annotate single image, given the complexity of the segmentation tasks. Thirdly, it is infeasible to deploy large deep learning models to edge devices for various medical tasks within a low-resource situation, especially with hardware constraints for practical clinical applications in the era of Telehealth and Metaverse.</p>
                    
                    <p>The vanilla deep learning models usually have limited ability of learning from sparse training samples. Consequently, to enable efficient and practical deep learning models for medical imaging, there is a need for research methods that can handle limited number of training data, limited labels and limited hardware constraints when deploying the model. To address the limited data challenge, recent methods related to data efficiency such as transfer learning, domain adaptation that can mitigate the domain shifts problem in medical imaging have been proposed in medical image analysis field. Besides, label efficiency methods such as partially-supervised learning, annotation-efficient learning and weakly supervised learning methods including semi-supervised, unsupervised, self-supervised as well as contrastive learning have been widely studied in this field including recent published work in MICCAI conferences etc. However, hardware efficiency related topics such as neural network compression, neural architecture search, etc has not been fully explored in the field. Therefore, in this workshop, we will encourage submissions on this topic to discuss the potential research problems raised by hardware efficiency, preparing for more AI applications for Metaverse and Telemedicine.
                    </p>

                        <h3>Details</h3>

                        We propose the below research topics from data, annotation and hardware perspectives for medical image analysis. Topics of interest include, but are not limited to: 
                        <ul>
                            <li><b>Data efficiency:</b>
                                <ul>
                                    <li>Transfer learning;</li>
                                    <li>Unsupervised domain adaptation;</li>
                                    <li>Single-shot/One-shot/Few-shot learning methods;</li>
                                    <li>Medical image classification/segmentation with small training dataset;</li>
                                </ul>
                            </li>
                            <li><b>Label efficiency:</b>
                                <ul>
                                    <li>Partial annotation/label learning methods;</li>
                                    <li>Weakly-supervised learning methods;</li>
                                    <li>Semi-supervised learning methods;</li>
                                    <li>Unsupervised learning methods;</li>
                                    <li>Self-supervised learning methods;</li>
                                    <li>Contrastive learning;</li>
                                </ul>
                            </li>
                            <li><b>Hardware efficiency:</b>
                                <ul>
                                    <li>Neural network compression;</li>
                                    <li>Knowledge distillation;</li>
                                    <li>Neural architecture search;</li>
                                    <li>Lightweight network design for medical image analysis;</li>
                                </ul>
                            </li>
                            <li><b>Resource-efficient learning for real-world applications:</b>
                                <ul>
                                    <li>Model deployment on low-resource devices;</li>
                                    <li>Knowledge distillation;</li>
                                    <li>Disease diagnosis, progression and treatment stratification with limited training data;</li>
                                    <li>New datasets and benchmark for resource-efficient learning in medical image analysis;</li>
                                </ul>
                            </li>

                        </ul>

                    </div>
                </div>
            </div>
        </div>
     </section>
 
 
     <section class="features section-padding" id="submit">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1"> 
                    <div class="intro-content">
                        <h2>Submission</h2> 
                        <ul>
                        <li>Papers should be limited to <b>8+2 pages</b> and formatted in Lecture Notes in Computer Science style. Please refer to the submission format guidelines of MICCAI 2023 and the Springer LNCS authors' information page for details (<a href="https://conferences.miccai.org/2023/en/PAPER-SUBMISSION-AND-REBUTTAL-GUIDELINES.html#manuscriptpreparation" target="_blank">https://conferences.miccai.org/2023/en/PAPER-SUBMISSION-AND-REBUTTAL-GUIDELINES.html</a>). Submissions are to be <b>anonymized</b> by removing author and institutional information from the author list on the title page. </li>
                        
                        <li>Please submit online following the <b>submission link</b> (<a href="https://cmt3.research.microsoft.com/REMIA2023" target="_blank">https://cmt3.research.microsoft.com/REMIA2023</a>).</li>
                        
                        <li>When submitting a paper, the authors implicitly acknowledge that <b>NO</b> paper of substantially similar content has been or will be submitted elsewhere. All accepted full papers will be published in Springer LNCS Proceedings. </li>
                    </ul>

                </div>
                </div>
            </div>
        </div>
    </section>

   <section class="features-list section-padding" id="program">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content">
                        <h2>Program</h2>

                    
                       <h3>Schedule</h3>

                       TBD
                       The REMIA Programme could be found in: >>><a href="./REMIA Program_2023.pdf" target="_blank"><strong>Programme</strong></a>
                       <!-- The REMIA Programme could be found in: >>><a href="./REMIA-Proramme.pdf" target="_blank"><strong>Programme</strong></a>. <br>
                       And the proceedings on Nature Springer has also been released: >>><a href="https://link.springer.com/book/10.1007/978-3-031-16876-5" target="_blank"><strong>Proceedings Link</strong></a>. -->
                       <br>


                        <h3>Keynote Speaker</h3> 
                        <table border="0" id="table1" width="100%">
 

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Russ Greiner 2020-07-20-095.jpg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Prof. Russ Greiner:</strong><br>
                                    <strong>"<i>Learning Models that Predict Objective, Actionable Labels</i>"</strong> <br>  
                                    <strong>Abstract:</strong>
                                    Many medical researchers want a tool that “does what a top medical clinician does, but does it better”.  This presentation explores this goal. This requires first defining what “better” means, leading to the idea of outcomes that are “objective” and then to ones that are actionable, with a meaningful evaluation measure. We will discuss some of the subtle issues in this exploration – what does “objective” mean, the role of the (perhaps personalized) evaluation function, multi-step actions, counterfactual issues, distributional evaluations, etc.  Collectively, this analysis argues we should learn models whose outcome labels are objective and actionable, as that will lead to tools that are useful and cost-effective.
                                    <br>
                                    <br>
                                    <i><strong>Bio:</strong>
                                    Prof. Russ Greiner worked in both academic and industrial research before settling at the University of Alberta, where he is now a Professor in Computing Science and the founding Scientific Director of the Alberta Machine Intelligence Institute. He has been Program/Conference Chair for various major conferences, and has served on the editorial boards of a number of ournals. He was elected a Fellow of the AAAI, has been awarded a McCalla Professorship and a Killam Annual Professorship; and in 2021, received the CAIAC Lifetime Achievement Award and became a CIFAR AI Chair. In 2022, the Telus World of Science museum honored him with a panel, and he received the (UofA) Precision Health Innovator Award, then in 2023, he received the CS-Can | Info-Can Lifetime Achievement Award.  For his mentoring, he received a 2020 FGSR Great Supervisor Award, then in 2023, the Killam Award for Excellence in Mentoring.  He has published over 300 refereed papers, most in the areas of machine learning and recently medical informatics, including 5 that have been awarded Best Paper prizes. The main foci of his current work are (1) bio- and medical- informatics; (2) survival prediction; and (3) formal foundations of learnability.
                                </i>
                                    
                                </td>
                            </tr>
                        </tbody> 


                    </table> 
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="features section-padding" id="awards">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="feature-list">
                        <h2>Awards</h2> 

                        <!-- <h3>Best paper award:</h3>
                        Keegan Quigley, Miriam Cha, Ruizhi Liao, Geeticka Chauhan, Steven Horng, Seth Berkowitz, and  Polina Golland, <strong>"RadTex: Learning Efficient Radiograph Representations from Text Reports"</strong>.

                        <p align="left">
                            <img border="0" src="photo/img-best-oral.jpg" width="400">
                        </p>

                        <h3>Best poster award:</h3>

                        Rudan Xiao, Damien Ambrosetti, and  Xavier Descombes, <strong>"Multi-Task Semi-Supervised Learning for Vascular Network Segmentation and Renal Cell Carcinoma Classification"</strong>.

                        <p align="left">
                            <img border="0" src="photo/img-best-poster.jpg" width="400">
                        </p>

                        <h3>Best paper runner-up:</h3>

                        Yanyu Xu, Xinxing Xu, Huazhu Fu, Meng Wang, Rick Siow Mong Goh, and  Yong Liu, <strong>"Facing Annotation Redundancy: OCT Layer Segmentation with Only 10 Annotated Pixels Per Layer"</strong>.
                        <p align="left">
                            <img border="0" src="photo/img-runner-up.jpg" width="400">
                        </p> -->
                        
                        Our workshop will select <b>one best paper award, one best paper runner-up, and one best poster award</b>.

                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="features-list section-padding" id="people">
    <div class="container">
        <div class="row">
            <div class="col-md-10 col-md-offset-1">
                <div class="intro-content">
                    <h2>Program Committee</h2>
                    <table border="0" id="table1" width="100%">
                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Xinxing.JPG" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Xinxing Xu</strong> <br>
                                    Institute of High Performance Computing (IHPC), A*STAR, Singapore. <br>
                                    <a href='mailto:xuxinx@ihpc.a-star.edu.sg'>xuxinx@ihpc.a-star.edu.sg</a> 
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/meng2.jpeg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Xiaomeng Li</strong> <br>
                                    The Hong Kong University of Science and Technology, Hongkong, China. <br>
                                    <a href='mailto:eexmli@ust.hk'>eexmli@ust.hk</a> 
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Dwarikanath.jpeg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Dwarikanath Mahapatra</strong> <br>
                            Inception Institute of Artificial Intelligence, Abu Dhabi, UAE. <br>
                            <a href='mailto:dwarikanath.mahapatra@inceptioniai.org'>dwarikanath.mahapatra@inceptioniai.org</a>
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Li_Cheng.jpg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Li Cheng</strong> <br>
                            ECE dept., University of Alberta, Canada. <br>
                            <a href='mailto:lcheng5@ualberta.ca'>lcheng5@ualberta.ca</a>
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/caro2.jpeg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Caroline Petitjean</strong>  <br>
                            LITIS, University of Rouen, France. <br>
                            <a href='mailto:caroline.petitjean@univ-rouen.fr'>caroline.petitjean@univ-rouen.fr</a>
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/presl-2940418-small.gif" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Benoît Presles</strong>  <br>
                                    ImViA laboratory, University of Burgundy, Dijon, France. <br>
                            <a href='mailto:benoit.presles@u-bourgogne.fr'>benoit.presles@u-bourgogne.fr</a>
                                </td>
                            </tr>
                        </tbody>

                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Bio_HzFU.JPG" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Huazhu Fu</strong> <br>
                            Institute of High Performance Computing (IHPC), A*STAR, Singapore. <br>
                            <a href='mailto:hzfu@ieee.org'>hzfu@ieee.org</a>
                                </td>
                            </tr>
                        </tbody>

                    </table> 


                    <!-- <h3>Local Organizers</h3> 
                    <table border="0" id="table1" width="100%">
                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/rick.jpeg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Rick Goh Siow Mong</strong> <br>
                                Institute of High Performance Computing (IHPC), A*STAR, Singapore. <br>
                                <a href='mailto:gohsm@ihpc.a-star.edu.sg'>gohsm@ihpc.a-star.edu.sg</a>
                                </td>
                            </tr>
                        </tbody>
                        
                        <tbody>
                            <tr>
                                <td style="width:25%">
                                    <p align="left">
                                        <img border="0" src="photo/Liu Yong.jpeg" width="150">
                                    </p>
                                </td>
                                <td>
                                    <strong>Yong Liu</strong> <br>
                            Institute of High Performance Computing (IHPC), A*STAR, Singapore. <br>
                            <a href='mailto:liuyong@ihpc.a-star.edu.sg'>liuyong@ihpc.a-star.edu.sg</a>
                                </td>
                            </tr>
                        </tbody>

                        

                    </table>  -->


                    <!-- <h3>Program Committee</h3>
                    <ul>

                        <li><strong>Behzad	Bozorgtabar</strong>,	EPFL </li> 
                        <li><strong>Élodie	Puybareau</strong>,	EPITA Research and Development Laboratory (LRDE)  </li> 
                        <li><strong>Erjian	Guo</strong>,	University of Sydney </li> 
                        <li><strong>He	Zhao</strong>,	Beijing Institute of Technology	 </li> 
                        <li><strong>Heng	Li</strong>, Southern University of Science and Technology </li> 
                        <li><strong>Jiawei	Du</strong>,	IHPC, A*STAR</li> 
                        <li><strong>Jinkui	Hao</strong>,	Cixi Institute of Biomedical Engineering, Ningbo Institute of Industrial Technology, CAS </li> 
                        <li><strong>Kang	Zhou</strong>,	ShanghaiTech University </li> 
                        <li><strong>Ke	Zou</strong>,	Sichuan university </li> 
                        <li><strong>Meng	Wang</strong>,	IHPC, A*STAR </li> 
                        <li><strong>Olfa	Ben Ahmed</strong>,	University of Poitiers </li> 
                        <li><strong>Pushpak	Pati</strong>,	IBM Research Zurich </li> 
                        <li><strong>Sarah	Leclerc</strong>,	University of Burgundy </li> 
                        <li><strong>Shaohua	Li</strong>,	IHPC, A*STAR </li> 
                        <li><strong>Shihao	Zhang</strong>,	National University of Singapore </li> 
                        <li><strong>Tao	Zhou</strong>,	Nanjing University of Science and Technology </li> 
                        <li><strong>Xiaofeng	Lei</strong>,	IHPC, A*STAR</li> 
                        <li><strong>Yan	Hu</strong>,	Southern University of Science and Technology </li> 
                        <li><strong>Yanmiao	Bai</strong>,	Cixi Institute of Biomedical Engineering, Ningbo Institute of Industrial Technology, CAS </li> 
                        <li><strong>Yanyu	Xu</strong>,	IHPC, A*STAR</li> 
                        <li><strong>Yiming	Qian</strong>,	IHPC, A*STAR</li> 
                        <li><strong>Yinglin	Zhang</strong>,	Southern University of Science and Technology </li> 
                        <li><strong>Yuming	Jiang</strong>,	Nanyang Technological University </li> 

                    </ul>    -->
                </div>
            </div>
        </div>
    </section>





    <section class="features section-padding" id="previous">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content"> 
                        <h2>Previous REMIA Workshops</h2>
                        <ul>
    
                            <li><a href='./prev_years/2022/index.html' target="_blank"><strong>1st REMIA 2022</strong></a></li>  
    
                        </ul>   
                    </div>
                </div>
            </div>
        </section>

            <!-- <section class="features-list section-padding" id="sponsors">
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="intro-content">
                        <h2>Sponsor</h2>  
                        <a href="https://www.a-star.edu.sg/" target="_blank"><img src="img/HTCO_AI3_Horizontal Logo_RGB.jpg" height="100px"></a>  
                    </div>
                </div>
            </div>
        </div>

    </section>  -->



    
    <section class="to-top">
        <div class="container">
            <div class="row"> 

                        <div class="col-xs-8">
                            <div class="to-top-wrap"> 
                    <a href="#top" class="top"><i class="fa fa-angle-up"></i></a>
                            </div>
                    </div>

                </div>
            </div>
        </div>
    </section> 


    


    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="js/vendor/jquery-1.11.2.min.js"><\/script>')</script>
    <script src="bower_components/retina.js/dist/retina.js"></script>
    <script src="js/jquery.fancybox.pack.js"></script>
    <script src="js/vendor/bootstrap.min.js"></script>
    <script src="js/scripts.js"></script>
    <script src="js/jquery.flexslider-min.js"></script>
    <script src="bower_components/classie/classie.js"></script>
    <script src="bower_components/jquery-waypoints/lib/jquery.waypoints.min.js"></script>
    <!-- Google Analytics: change UA-XXXXX-X to be your site's ID. -->
    <script>
    (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
    function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
    e=o.createElement(i);r=o.getElementsByTagName(i)[0];
    e.src='//www.google-analytics.com/analytics.js';
    r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
    ga('create','UA-XXXXX-X','auto');ga('send','pageview');
    </script>


</body>
</html>
